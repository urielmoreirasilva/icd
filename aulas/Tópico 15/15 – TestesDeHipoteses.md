# T√≥pico 15 ‚Äì Testes de Hip√≥teses [<img src="images/colag_logo.svg" style="float: right; vertical-align: middle; width: 42px; height: 42px;">](https://colab.research.google.com/github/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas/T%C3%B3pico%2015/15%20%E2%80%93%20TestesDeHipoteses.ipynb) [<img src="images/github_logo.svg" style="float: right; margin-right: 12px; vertical-align: middle; width: 36px; height: 36px;">](https://github.com/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas/T%C3%B3pico%2015/15%20%E2%80%93%20TestesDeHipoteses.ipynb)

Nessa aula, voltamos nossa aten√ß√£o para uma pergunta fundamental em Ci√™ncia de Dados: "como testar se um conjunto de hip√≥teses feitas sobre os dados √© adequado ou n√£o?". Para responder essa pergunta, introduziremos a no√ß√£o de modelos estat√≠sticos e um conjunto de m√©todos desenhado especificamente para verificar a utilidade desses modelos na pr√°tica, denominados de Testes de Hip√≥teses.

### Resultados Esperados 

1. Aprender a definir o que s√£o modelos estat√≠sticos, e a formular problemas pr√°ticos em Ci√™ncia de Dados como modelos.
1. Introduzir o conceito de signific√¢ncia estat√≠stica, e a caracteriza√ß√£o da "quantidade de erro aleat√≥rio" que estamos dispostos a permitir em situa√ß√µes pr√°ticas.
1. Introduzir as no√ß√µes b√°sicas de Testes de Hip√≥teses, e a utilizar essa metodologia para testar a adequa√ß√£o de diferentes modelos estat√≠sticos em problemas de an√°lises de dados.

### Refer√™ncias
- [CIT, Cap√≠tulo 11](https://inferentialthinking.com/)

Material adaptado do [DSC10 (UCSD)](https://dsc10.com/) por [Flavio Figueiredo (DCC-UFMG)](https://flaviovdf.io/fcd/) e [Uriel Silva (DEST-UFMG)](https://urielmoreirasilva.github.io)


```python
# Imports para esse t√≥pico (note que aqui temos um novo m√≥dulo nessa lista: o SciPy!).
import numpy as np
import babypandas as bpd
import pandas as pd
import matplotlib.pyplot as plt
import scipy as scipy
plt.style.use('ggplot')

# Op√ß√µes de como printar objetos do Numpy e do Pandas.
np.set_printoptions(threshold = 20, precision = 2, suppress = True)
pd.set_option("display.max_rows", 7)
pd.set_option("display.max_columns", 8)
pd.set_option("display.precision", 2)
```

## Modelos Estat√≠sticos

### Modelos

- Informalmente, um **modelo estat√≠stico** consiste de um conjunto de hip√≥teses sobre o qual fazemos sobre o processo que gerou nossos dados.
- Exemplos simples de modelos s√£o:
    - Moedas "justas" t√™m probabilidade igual (50%) de cara e coroa.
    - Dados "justos" t√™m probabilidade igual (1/6) para cada um dos lados.
    - A gravidez de uma f√™mea Golden Retriever pode resultar em 1 at√© 14 (!) filhotes, com m√©dia entre 7 e 8.

- Um dos principais objetivos em Infer√™ncia Estat√≠stica √© **aferir a qualidade de um modelo**.
    - Em outras palavras, buscamos aferir o **qu√£o bem um modelo explica a "realidade"** refletida nos dados.  

- Conforme aprendemos at√© agora, a maioria dos problemas em Infer√™ncia pode ser resolvido atrav√©s de alguma teoria (baseada em Matem√°tica e Probabilidade) e tamb√©m com t√©cnicas de simula√ß√£o.

- Em ambos os casos, vamos sempre **assumir que o nosso modelo seja verdadeiro**, e ent√£o calcular as frequ√™ncias/probabilidades com as quais os padr√µes observados nos nossos dados ocorreriam sob esse modelo. 

- Em geral, o processo de verificar se um modelo √© adequado ou n√£o para um certo conjunto de dados √© denominado de **teste de hip√≥tese**. Definiremos essa no√ß√£o mais formalmente abaixo.

### Exemplo: lan√ßamento de uma moeda

Suponha que voc√™ queira decidir se uma certa moeda √© "justa", isto √©, se no lan√ßamento dessa moeda a probabilidade de uma cara √© igual a probabilidade de uma coroa (isto √©, 1/2 ou 50%).

Para verificar isso, voc√™ lan√ßa a moeda $n = 400$ vezes, anotando os resultados obtidos.


```python
flips_400 = bpd.read_csv('data/flips-400.csv')
flips_400
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>flip</th>
      <th>outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Tails</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Tails</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Tails</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>397</th>
      <td>398</td>
      <td>Heads</td>
    </tr>
    <tr>
      <th>398</th>
      <td>399</td>
      <td>Heads</td>
    </tr>
    <tr>
      <th>399</th>
      <td>400</td>
      <td>Tails</td>
    </tr>
  </tbody>
</table>
<p>400 rows √ó 2 columns</p>
</div>




```python
flips_400.groupby('outcome').count()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>flip</th>
    </tr>
    <tr>
      <th>outcome</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Heads</th>
      <td>188</td>
    </tr>
    <tr>
      <th>Tails</th>
      <td>212</td>
    </tr>
  </tbody>
</table>
</div>



- Naturalmente, surge ent√£o a seguinte pergunta: **esse resultado √© consistente ou n√£o** com o nosso "modelo", isto √©, com a _hip√≥tese_ de que a moeda √© justa?
    - Em outras palavras, qu√£o _prov√°vel_ (ou improv√°vel) seria obtermos 188 caras em 400 lan√ßamentos de uma moeda justa?

## Signific√¢ncia Estat√≠stica

- Antes de introduzirmos o ferramental necess√°rio para responder √† pergunta acima, primeiramente vamos refletir um pouco sobre a seguinte pergunta:

> Se esperamos _exatamente_ uma propor√ß√£o de 50% de caras nos lan√ßamentos da moeda do exemplo anterior, quais as propor√ß√µes $p$ de caras aceitar√≠amos como **estatisticamente iguais** a 50%? O que nesse caso seria uma "diferen√ßa inaceit√°vel" entre $p$ e 50% para decidirmos que a moeda n√£o √© justa?  

- Para responder perguntas como essa, frequentemente utilizamos o conceito de **signific√¢ncia estat√≠stica**. 

- Basicamente, um resultado √© considerado **estatisticamente significante** se sua ocorr√™ncia por pura chance/aleatoriedade/"coincid√™ncia" √© considerada **baixa**.
- Mais formalmente, um evento √© considerado estatisticamente significante se sua probabilidade √© **menor** do que um certo valor $\alpha \in (0, 1)$.
    - Denominamos $\alpha$ ent√£o de **n√≠vel de signific√¢ncia**. Um n√≠vel de signific√¢ncia muito comum utilizado na pr√°tica √© $\alpha = 5\%$.

- O _complementar_ do n√≠vel de signific√¢ncia $\alpha$ √© o n√≠vel de confian√ßa $\gamma$ que vimos anteriormente, isto √©, $\alpha + \gamma = 1$.
    - Escolher um n√≠vel de signific√¢ncia de $\alpha = 5\%$ √© ent√£o equivalente a escolher um n√≠vel de confian√ßa de $\gamma = 1 - \alpha = 95\%$.

### De volta ao exemplo da moeda

- _Supondo que a moeda seja justa_, qual a probabilidade de ocorrerem entre 188 e 212 caras em $n = 400$ lan√ßamentos?

- Omitindo as tecnicalidades, essa probabilidade √© dada por (lembre do Tri√¢ngulo de Pascal!)

\begin{equation*}
    \sum^{212}_{k = 188} {n \choose k} \left(\frac{1}{2}\right)^k \left(\frac{1}{2}\right)^{n-k} \simeq 0.7693,
\end{equation*}

ou 76.93%.

- No Python, podemos calcular essa probabilidade atrav√©s da fun√ß√£o de distribui√ß√£o acumulada da _Distribui√ß√£o Binomial_, `scipy.stats.binom.cdf`.
    - Essa √© outra distribui√ß√£o que voc√™ ver√° nos pr√≥ximos cursos!
    - Os par√¢metros dessa fun√ß√£o s√£o `x` $(x \in \mathbb{R})$, o n√∫mero de experimentos `n` $(n \in \mathbb{N})$ e a probabilidade de sucesso de cada experimento, `p` $(0 < p < 1)$.
    - Como toda fun√ß√£o de distribui√ß√£o acumulada, para calcular a probabilidade dos valores no intervalo $[a, b]$, fazemos $F(b) - F(a)$.


```python
scipy.stats.binom.cdf(212, 400, .5) - scipy.stats.binom.cdf(188, 400, .5)
```




    0.7693207085127098



- Dessa forma, _se a moeda for justa_, a probabilidade de obtermos um n√∫mero de caras entre 188 e 212 √© bem alta!
- Analogamente, a probabilidade de obtermos um n√∫mero de caras **menor** que 188 e **maior** que 212 ser√° ent√£o igual a $1 - 0.7639 \simeq 0.2307$


```python
1 - (scipy.stats.binom.cdf(212, 400, .5) - scipy.stats.binom.cdf(188, 400, .5))
```




    0.23067929148729016



- O resultado acima nos diz ent√£o que, ainda que a moeda seja justa, em $n = 400$ lan√ßamentos a probabilidade de obtermos algo em torno de 188 a 212 caras √© bem razo√°vel.
- Em outras palavras, como $188/400 = 0.47$ e $212/400 = 0.53$, desvios de at√© $3\%$ no n√∫mero esperado de caras ($50\%$) em $n = 400$ lan√ßamentos de uma moeda ocorrem com uma probabilidade de $23.07\%$.

- Dessa forma, uma ocorr√™ncia de 188 caras em 400 lan√ßamentos **n√£o √© considerada significativa** a um n√≠vel $\alpha = 5\%$!

- O que seria ent√£o considerado estatisticamente significante nesse problema? ü§î


```python
heads = 181
1 - (scipy.stats.binom.cdf(400 - heads, 400, .5) - scipy.stats.binom.cdf(heads, 400, .5))
```




    0.05760952246249662




```python
heads = 180
1 - (scipy.stats.binom.cdf(400 - heads, 400, .5) - scipy.stats.binom.cdf(heads, 400, .5))
```




    0.04563548140489304



- Se tomarmos um n√≠vel de signific√¢ncia de $\alpha = 5\%$, observar de 181 a 219 caras (desvios de at√© 4.75%) ainda seria considerado "aceit√°vel" (i.e. n√£o-significante) nesse caso.
- Precisar√≠amos de um resultado mais extremo (e desvios maiores, maiores ou iguais 5%) para ser considerado estatisticamente significante, como por exemplo 180 caras ou menos, ou 220 caras ou mais. 

> Para concluir nosso exemplo (e mais uma vez note que vamos voltar a esse ponto mais adiante), lembrando da complementariedade entre o n√≠vel de confian√ßa $\gamma$ e o n√≠vel de signific√¢ncia $\alpha$, podemos obter a _mesma resposta acima_ atrav√©s de um intervalo de 95% de confian√ßa para a propor√ß√£o populacional de caras em uma moeda justa, que podemos calcular atrav√©s de:


```python
scipy.stats.binom.interval(0.95, 400, .5)
```




    (180.0, 220.0)



## Testes de Hip√≥teses

### No√ß√µes b√°sicas

- Podemos definir um **Teste de Hip√≥teses** como um procedimento em que testamos a **hip√≥tese de que o nosso modelo esteja correto** contra a **hip√≥tese de que o nosso modelo n√£o esteja correto**.
    - A primeira hip√≥tese, isto √©, de que o nosso modelo esteja correto √© denominada de **hip√≥tese nula**.
    - A segunda hip√≥tese, isto √©, de que o nosso modelo n√£o esteja correto √© denominada de **hip√≥tese alternativa**.
- A **aceita√ß√£o** de uma hip√≥tese em detrimento da outra leva √† **rejei√ß√£o** da outra hip√≥tese.

- **Muito importante:** Embora estejamos definindo os Testes de Hip√≥teses e nossos modelos em termos como "aceita√ß√£o" e "correto", note que na verdade o procedimento apenas nos diz se o modelo postulado √© _condizente_ com os padr√µes observados nos nossos dados.
    - Dessa forma, como em geral o processo gerador dos dados √© _aleat√≥rio_, podemos aceitar a hip√≥tese de um modelo esteja correto (ou errado) por _pura aleatoriedade_, sem que na verdade o modelo seja _verdadeiramente_ correto (ou errado)!

- Em vista da observa√ß√£o acima, uma outra maneira de pensarmos no n√≠vel de signific√¢ncia √© como um **n√≠vel m√°ximo permitido** para a influ√™ncia da incerteza/aleatoriedade sobre o nosso experimento/processo gerador de dados.
    - Equivalentemente, $\alpha$ representa **a frequ√™ncia m√°xima com a qual nosso modelo (ainda que esteja correto) possa ser rejeitado por um teste de hip√≥teses**.

> No exemplo acima, embora 400 lan√ßamentos de uma moeda justa possam _de fato_ produzir menos de 180 caras (ou mais de 220), a _probabilidade_ com a qual isso ocorre √© menor que $\alpha$.
> > Reiterando sobre esse ponto, _ainda que nosso modelo esteja correto_, a probabilidade desse resultado ocorrer por pura aleatoriedade √© _t√£o baixa_ que consideramos que √© mais _plaus√≠vel_ que nosso modelo esteja errado! 

- Finalmente, como para cada hip√≥tese nula fazemos um teste separado, √© poss√≠vel que **aceitemos v√°rias hip√≥teses nulas diferentes** e, logo, **v√°rios modelos diferentes**, para os mesmos dados.
    - Embora existam algumas maneiras de contornar esse problema (voc√™ ver√° isso nos pr√≥ximos cursos!), essa √© uma caracter√≠stica **inerente** n√£o somente aos Testes de Hip√≥teses, mas √† Infer√™ncia Estat√≠stica como um todo.
    - Lembre da nossa discuss√£o anterior sobre **igualdade estat√≠stica**: com 95% de confian√ßa, todas as propor√ß√µes $p \in (0.45, 0.55)$ s√£o _igualmente prov√°veis_ (inclusive $p = 0.50$!) nesse experimento.

### Hip√≥teses nulas e alternativas

- Vamos agora formalizar as no√ß√µes de hip√≥teses dadas acima.

- No exemplo da moeda justa, nossa hip√≥tese nula √©
    - "a moeda √© justa".
- Analogamente, nossa hip√≥tese alternativa √©
    - "a moeda n√£o √© justa".

- Em um teste de hip√≥teses, a hip√≥tese nula deve ser um **modelo de probabilidade bem definido** sobre o processo que gerou nossos dados.
    - Precisamos disso para poder calcular todas as probabilidades e frequ√™ncias sobre as quais estamos interessados, n√£o s√≥ do ponto de vista _te√≥rico/matem√°tico_ como tamb√©m do ponto de vista _pr√°tico/computacional_.
    - Em outras palavras: precisamos definir bem um modelo para simular desse modelo!
    - Usualmente denotamos a hip√≥tese nula por $H_0$.

- Mais uma vez voltando ao nosso exemplo, uma poss√≠vel hip√≥tese nula aqui seria $H_0: p_0 = 0.5$, onde $p_0$ representa a probabilidade do lan√ßamento de uma moeda resultar em cara.
    - Tecnicamente, para que esse modelo esteja realmente bem definido definimos uma vari√°vel aleat√≥ria tomando valores no espa√ßo amostral $\{H, T\}$ com probabilidades $p_0$ e $1 - p_0$, respectivamente.

- Por outro lado, a **hip√≥tese alternativa** representa uma _vis√£o diferente_ (e usualmente complementar, para que o **teste** esteja bem definido) do processo que gerou nossos dados.
    - Dessa forma, a hip√≥tese alternativa **n√£o precisa ser espec√≠fica**, uma vez que basta a hip√≥tese nula _ser rejeitada_ para que a hip√≥tese alternativa seja aceita.
    - Usualmente denotamos a hip√≥tese alternativa por $H_1$. 

- Retornando ao exemplo da moeda, uma poss√≠vel hip√≥tese alternativa seria $H_1:p_0 \neq 0.5$.
    - Note que essa √© uma hip√≥tese bem vaga, assim como "a moeda n√£o √© justa", pois _qualquer valor_ para a propor√ß√£o de caras diferente de $0.5$ satisfaz a hip√≥tese alternativa.

### Estat√≠sticas de teste

- Uma vez definidas $H_0$ e $H_1$, come√ßamos nossa infer√™ncia **supondo que a hip√≥tese nula $H_0$ seja verdadeira**.

- **Sob $H_0$**, calcularemos ent√£o uma quantidade que denominaremos de **estat√≠stica de teste** (usualmente denotada por $T$).
    - Como o pr√≥prio nome implica, essa ser√° uma **estat√≠stica** (e logo calculada com base na amostra) utilizada para realizarmos nosso teste.
    - Em ess√™ncia, a estat√≠stica de teste objetiva medir a evid√™ncia _a favor_ (ou _contra_) $H_0$. 

- Se utilizarmos a teoria Estat√≠stica/matem√°tica para conduzir nosso teste de hip√≥tese, calculamos _uma √∫nica estat√≠stica de teste_ sob $H_0$, e essencialmente utilizamos a teoria para saber se o **valor observado** (usualmente denotado por $T_{obs}$) √© _estatisticamente significante_.
    - Por exemplo, sob o TCL, sabemos que 95% dos valores de uma distribui√ß√£o Normal est√£o a ¬± 2 DPs da m√©dia. Dessa forma, se sob $H_0$ temos $\mu = 10$ e $\sigma/\sqrt{n} = 1$, um valor para $T_{obs} = \bar{X}$ menor que 8 e maior que 12 seria considerado estatisticamente significante sob $\alpha = 5\%$. 

- Por outro lado, se utilizarmos simula√ß√£o, teremos _uma estat√≠stica de teste para cada amostra_ produzida sob $H_0$.
    - Com um n√∫mero grande de amostras, produzimos ent√£o uma aproxima√ß√£o para a distribui√ß√£o de probabilidade da estat√≠stica de teste $T$, e verificamos se o valor observado $T_{obs}$ √© estatisticamente significante nessa distribui√ß√£o.
    - A verifica√ß√£o de signific√¢ncia nesse caso consiste essencialmente em verificar √† _qual percentil dessa distribui√ß√£o_ corresponde o valor de $T_{obs}$.

### Simulando sob $H_0$

- Voltando ao nosso exemplo anterior, podemos simular `n` lan√ßamentos de uma moeda justa utilizando a fun√ß√£o `np.random.binomial(n, 0.5)`.
    - Lembre que aqui simulamos sob $H_0$, e simular sob $H_1$ seria imposs√≠vel (existem infinitos n√£o-enumer√°veis valores de $p_0$ que satisfazem a defini√ß√£o de "moeda injusta").

- Como estamos interessados na propor√ß√£o de caras, nossa estat√≠stica de teste $T$ ser√° o n√∫mero de caras em cada simula√ß√£o.
    - Calculamos ent√£o $T_{obs}$ para cada amostra produzida, anotamos o valor correspondente e dessa forma constru√≠mos uma distribui√ß√£o emp√≠rica para a estat√≠stica de teste $T$ sob $H_0$.


```python
# Computes a single simulated test statistic.
np.random.binomial(400, 0.5)
```




    210




```python
# Computes 10,000 simulated test statistics.
np.random.seed(42)

results = np.array([])
for i in np.arange(10000):
    result = np.random.binomial(400, 0.5)
    results = np.append(results, result)
    
results
```




    array([193., 194., 202., ..., 201., 201., 192.])



### Distribui√ß√£o emp√≠rica da estat√≠stica de teste

Vamos agora visualizar a distribui√ß√£o emp√≠rica da estat√≠stica de teste sob $H_0$:


```python
bpd.DataFrame().assign(results=results).plot(kind='hist', bins=np.arange(160, 240, 4), 
                                             density=True, ec='w', figsize=(10, 5),
                                             title='Distribui√ß√£o Emp√≠rica do N√∫mero de Caras em $n = 400$ Lan√ßamentos de uma Moeda Justa');
plt.axvline(188, color='black', linewidth=4, label='observed statistic (188)')
plt.legend()
plt.ylabel("Frequ√™ncia");
```


    
![png](15%20%E2%80%93%20TestesDeHipoteses_files/15%20%E2%80%93%20TestesDeHipoteses_57_0.png)
    


- Se observ√°ssemos $T_{obs} = 200$ caras, naturalmente aceitar√≠amos $H_0$, isto √©, que nossa moeda √© justa.

- Analogamente, rejeitar√≠amos $H_0$ (isto √©, concluir√≠amos que nossa moeda √© injusta) se:
    - observ√°ssemos "poucas caras".
    - observ√°ssemos "muitas caras".

- Mas como decidimos o que seriam "poucas" e "muitas" nesse contexto?

### Valores Cr√≠ticos e Regi√µes de Aceita√ß√£o

- Dada a nossa discuss√£o acima sob signific√¢ncia estat√≠stica, seria natural **rejeitarmos $H_0$ se a probabilidade de observarmos $T_{obs}$ for muito baixa**.

- No exemplo anterior, vimos (teoricamente) que a probabilidade de que $T \leq 180$ ou que $T \geq 220$ √© pouco menos que 5%.
    - Dessa forma, valores **t√£o extremos** quanto $T \leq 180$ ou $T \geq 220$ s√£o considerados **estatisticamente significantes** (ao n√≠vel de $\alpha = 5\%$), e logo indicativos de que $H_0$ n√£o √© verdadeira.

- Na distribui√ß√£o simulada anteriormente, podemos encontrar esses valores como os percentis 2.5% e 97.5%, respectivamente.


```python
np.percentile(results, 2.5)
```




    180.0




```python
np.percentile(results, 97.5)
```




    220.0



- Ao n√≠vel de $\alpha = 5\%$ de signific√¢ncia, dizemos que $c_1 = 180$ e $c_2 = 220$ s√£o ent√£o os **n√≠veis cr√≠ticos** (ou valores cr√≠ticos) desse teste de hip√≥teses.

- Mais formalmente, os **n√≠veis cr√≠ticos** de um teste s√£o valores $c_1 < c_2$ tais que **$H_0$ √© rejeitada ao n√≠vel $\alpha\%$ de signific√¢ncia** caso $T_{obs} < c_1$ _ou_ $T_{obs} > c_2$.
    - Note que formalmente sempre frisamos "ao n√≠vel $\alpha\%$ de signific√¢ncia", pois os n√≠veis cr√≠ticos $c_1$ e $c_2$ sempre ser√£o fun√ß√µes de $\alpha$.

- Quando simulamos a distribui√ß√£o de $T$ sob $H_0$, $c_1$ e $c_2$ s√£o simplesmente dados pelos percentis $\alpha/2$ e $1 - \alpha/2$ dessa distribui√ß√£o, respectivamente.
    - Analogamente, se utilizarmos alguma teoria ou aproxima√ß√£o (por exemplo o TCL), $c_1$ e $c_2$ ser√£o dados pelos percentis correspondentes da distribui√ß√£o correspondente (por exemplo a Normal).

- Na nomenclatura usual de Testes de Hip√≥teses, o conjunto de pontos entre $c_1$ e $c_2$ definem a **Regi√£o de Aceita√ß√£o** do teste.
    - Formalmente, $RA := \{T_{obs}: c_1 \leq T_{obs} \leq c_2\}$.
    - Como o pr√≥prio nome implica, _aceitamos $H_0$ para todos os valores_ $T_{obs} \in RA$.

- Em contrapartida, o conjunto de pontos menores que $c_1$ e maiores que $c_2$ definem a **Regi√£o de Rejei√ß√£o** (ou Regi√£o Cr√≠tica) do teste.
    - Formalmente, $RC := \{T_{obs}: T_{obs} < c_1 \,\text{ou}\,\,\, T_{obs} > c_2\}$.
    - Como o pr√≥prio nome implica, _rejeitamos $H_0$ para todos os valores_ $T_{obs} \in RC$.

- Finalmente, como s√≥ existem 2 resultados para um teste de hip√≥teses (isto √©, ou aceitamos ou rejeitamos $H_0$), ent√£o $RA$ e $RC$ s√£o complementares, isto √©,

\begin{equation*}
    T_{obs} \in RA \Leftrightarrow T_{obs} \notin RC
\end{equation*}

e vice-versa.

### Testes de Hip√≥teses via Intervalos de Confian√ßa

- Uma outra maneira de interpretar a Regi√£o de Aceita√ß√£o conforme definida acima √© como um conjunto de pontos em que os valores observados para uma certa estat√≠stica de teste $T$ s√£o _estatisticamente iguais_ sob $H_0$.
    - No nosso exemplo, todas as propor√ß√µes de caras observadas entre $c_1/400 = 180/400 = 0.45$ e $c_2/400 = 220/400 = 0.55$ s√£o _igualmente prov√°veis_, e consistentes (para essa amostra, de tamanho $n = 400$) com $H_0: p_0 = 0.50$.
    - Essa interpreta√ß√£o √© muito similar √† de um Intervalo de Confian√ßa!

- De fato, existe uma rela√ß√£o natural, direta e intr√≠nseca entre os Testes de Hip√≥teses e Intervalos de Confian√ßa.
    - Mais especificamente, lembrando que $\gamma = 1 -\alpha$, um IC de $\gamma\%$ para o par√¢metro de interesse **sempre cont√©m todos os valores hipotetizados para o par√¢metro de interesse que levariam √† aceita√ß√£o de $H_0$!**.

Retornando ao exemplo anterior, temos $T_{obs} = 188$ em $n = 400$ lan√ßamentos da moeda.

Utilizando propriedades da distribui√ß√£o Binomial, o IC95% para o _n√∫mero de caras_ √© dado por


```python
T_obs = 188
n = 400
gamma = 0.95
```


```python
scipy.stats.binom.interval(gamma, n, T_obs/n)
```




    (168.0, 208.0)



Por outro lado, $T_{obs} = 188$ em $n = 400$ lan√ßamentos se traduz em uma propor√ß√£o de caras estimada igual a $p_{obs} = 0.47$.


```python
p_obs = T_obs/n
p_obs
```




    0.47



O IC95% para a propor√ß√£o de caras √© dado ent√£o por


```python
CI = scipy.stats.binom.interval(gamma, n, p_obs)
left = CI[0]/n
right = CI[1]/n

[left, right]
```




    [0.42, 0.52]



- Conclu√≠mos dessa forma que, embora a propor√ß√£o de caras observada $p_{obs} = 0.47$ n√£o tenha sido _exatamente_ (ou _numericamente_) igual a $p_0 = 0.50$, a _propor√ß√£o populacional_ de caras √© estatisticamente igual a $p_0 = 0.50$ (com 95% de confian√ßa), uma vez que esse valor est√° contido dentro do IC95%.

Para essa amostra, **qualquer hip√≥tese do tipo $H_0: p_0 = p^*$ para $p^* \in [0.42, 0.52]$ seria aceita** ao n√≠vel $\alpha = 5\%$!

### p-valores

- Apesar dos crit√©rios estabelecidos para a aceita√ß√£o/rejei√ß√£o de $H_0$ acima serem definidos de maneira **precisa**, as regras de rejei√ß√£o s√£o **bin√°rias**, e logo "r√≠gidas".
    - Ou aceitamos ou rejeitamos $H_0$, _independente_ do "qu√£o distante" a estat√≠stica de teste $T_{obs}$ se encontra dos pontos cr√≠ticos $c_1$ e $c_2$.

- Nesse contexto, frequentemente surgem perguntas do tipo: dado que $H_0$ √© rejeitada para $T_{obs}$, o qu√£o "extremo" √© o valor de $T_{obs}$?
    - Em outras palavras, qual a probabilidade de obtermos de um valor de $T_{obs}$ _mais distante_ de $c_1$ (ou $c_2$)?

- A quantifica√ß√£o da dist√¢ncia de $T_{obs}$ com rela√ß√£o aos n√≠veis cr√≠ticos $c_1$ e $c_2$ √© dada por uma quantidade que denominamos de **p-valor**.

- Mais precisamente, um p-valor $p$ √© definido como a probabilidade (sob $H_0$) da nossa estat√≠stica de teste $T$ ser menor/maior do que $T_{obs}$, **na dire√ß√£o em que rejeitamos $H_0$**.

- No exemplo anterior, como a distribui√ß√£o de $T$ sob $H_0$ est√° centrada em $m = 200$ e nossa hip√≥tese nula diz respeito ao fato da moeda ser justa, temos $c_1 = 180$, $c_2 = 220$, e:
    - se $T_{obs} < m$, ent√£o $p$ √© dado pela soma da **cauda √† esquerda de $T_{obs}$** com a **cauda √† direita de $2m - T_{obs}$** da distribui√ß√£o de $T$ sob $H_0$.
    - se $T_{obs} > m$, ent√£o $p$ √© dado pela soma da **cauda √† esquerda de $2m - T_{obs}$** com a **cauda √† direita de $T_{obs}$** da distribui√ß√£o de $T$ sob $H_0$.

Para calcular esse valor, basta calcularmos as frequ√™ncias correspondentes na distribui√ß√£o de $T$ simulada sob $H_0$:  


```python
T_obs = 188
p_lower = np.count_nonzero(results <= T_obs) / len(results)
p_upper = np.count_nonzero(results >= 2*200 - T_obs) / len(results)
p = p_lower + p_upper
p
```




    0.253



Naturalmente, como os percentis 2.5% e 97.5% da nossa distribui√ß√£o emp√≠rica para $T$ $c_1 = 180$ e $c_2 = 220$, **qualquer valor de $T_{obs}$ tal que $T_{obs} < c_1$ ou $T_{obs} > c_2$ ter√° um p-valor menor que $\alpha = 5\%$!**


```python
T_obs = 179
p_lower = np.count_nonzero(results <= T_obs) / len(results)
p_upper = np.count_nonzero(results >= 2*200 - T_obs) / len(results)
p = p_lower + p_upper
p
```




    0.0435




```python
T_obs = 221
p_lower = np.count_nonzero(results <= 2*200 - T_obs) / len(results)
p_upper = np.count_nonzero(results >= T_obs) / len(results)
p = p_lower + p_upper
p
```




    0.0435



- O resultado acima pode ser elaborado em geral da seguinte forma: **se $T_{obs} \in RA$, ent√£o $T_{obs} \geq \alpha$**.
    - Analogamente, se $T_{obs} \notin RA$, ent√£o $T_{obs} \leq \alpha$.

- Dessa forma, **podemos utilizar o p-valor diretamente para conduzir um teste de hip√≥teses**, pois
    - se $p \geq \alpha$, ent√£o $T_{obs} \in RA$ e aceitamos $H_0$;
    - se $p < \alpha$, ent√£o $T_{obs} \notin RA$ e rejeitamos $H_0$.

Note que a possibilidade de que $p = \alpha$ n√£o ocorre na pr√°tica, pois $0 < p < 1$ √© real (tecnicamente esse √© um _evento que ocorre com probabilidade zero_ ‚Äì voc√™ ver√° mais sobre isso em outros cursos).

- Em vista do argumento acima, √© comum denominar o p-valor de _n√≠vel de signific√¢ncia observado_, pois dado $T = T_{obs}$, o p-valor √© igual _ao menor valor de $\alpha$ tal que $H_0$ seja rejeitada_.

**Importante**: existe _muita_ controv√©rsia em torno do uso de p-valores na condu√ß√£o de Testes de Hip√≥teses, e a principal fonte de controv√©rsia √© dada ao tentar interpretar o p-valor como uma probabilidade.

Da defini√ß√£o de n√≠vel signific√¢ncia observado acima, note que embora _calculemos_ o p-valor como uma probabilidade, $p$ depende de um _valor observado_ na amostra, isto √©, $T_{obs}$.

> Dessa forma, o p-valor √© na verdade uma **estat√≠stica**, e **n√£o uma probabilidade**!

Embora esse ponto seja bem sutil e ser√° elaborado (repetidamente) de maneira cada vez mais adequada nos pr√≥ximos cursos, √© importante lembrar que, como _o processo de amostragem √© aleat√≥rio_, **um valor mais/menos extremo de $T_{obs}$ n√£o significa uma evid√™ncia mais/menos forte contra $H_0$**, pois flutua√ß√µes nos valores de $T$ s√£o _naturalmente esperadas devido √† aleatoriedade_. 

- Finalmente, embora o p-valor seja muito √∫til para caracterizar melhor as quantidades envolvidas em um Teste de Hip√≥teses (e logo dar mais interpretabilidade aos resultados obtidos), **no fim das contas aceitar ou rejeitar $H_0$ √© sempre uma decis√£o bin√°ria**.

### Conclus√µes de um Teste de Hip√≥teses

- Com base no teste de hip√≥tese realizado no exemplo anterior, a diferen√ßa de $p_{obs} - p_0 = -0.03$ observada no nosso processo de amostragem pode ent√£o, _ao n√≠vel de signific√¢ncia de $\alpha = 5\%$_, **ser puramente atribu√≠da ao acaso**!
    - Como o teste que constru√≠mos √© _sim√©trico_, uma diferen√ßa de $p_0 - p_{obs} = 0.03$ tamb√©m n√£o seria considerada estatisticamente significante.

Em geral, _qualquer valor_ de $p_{obs}$ no intervalo $RA = [0.45, 0.55]$ que fosse observado para essa amostra de tamanho $n = 400$ seria consistente com a hip√≥tese de que a moeda √© justa.

Analogamente, valores de $p_{obs}$ menores que $0.45$ ou maiores que $0.55$ (ou diferen√ßas maiores que $0.05$ em m√≥dulo) seriam considerados _estatisticamente significantes_, e logo n√£o seriam consistentes com $H_0$ ao n√≠vel de $\alpha = 5\%$ de signific√¢ncia.

- O IC95% complementa a conclus√£o acima com a informa√ß√£o de que, para essa amostra, _qualquer valor_ $p_0$ no intervalo $[0.42, 0.52]$ seria plaus√≠vel como a propor√ß√£o _real_ de caras obtidas em um lan√ßamento dessa moeda.
    - Inclusive $p_0 = 0.50$!

Podemos dizer ent√£o com 95% de confian√ßa que a moeda √© justa, uma vez que a propor√ß√£o $p_0 = 0.50$ se encontra dentro do IC95%.

- Finalmente, o p-valor do teste de $p = 0.2486$ nos diz que um resultado como $T_{obs} = 188$ caras ou uma propor√ß√£o de $p_{obs} = 0.47$ em $n = 400$ lan√ßamentos de _uma moeda justa_ (isto √©, sob $H_0$) n√£o √© t√£o at√≠pico assim.

N√£o podemos dizer ent√£o que esse √© um resultado significante, pois a probabilidade de obtermos um resultado como esse por puro acaso √© de 24.86%, o que ao n√≠vel de $\alpha = 5\%$ √© considerada aceit√°vel.

**Nota**: assim como podemos utilizar tanto simula√ß√£o quanto teoria para aproximar a distribui√ß√£o da estat√≠stica de teste, o mesmo vale para a constru√ß√£o dos intervalos de confian√ßa e o c√°lculo dos p-valores correspondentes.

## Resumo
- Um modelo estat√≠stico pode ser formulado como um conjunto de hip√≥teses que elaboramos sobre o processo que gerou nossos dados.
- Para verificar a adequa√ß√£o de um modelo estat√≠stico, realizamos um **Teste de Hip√≥teses**.
- A **hip√≥tese nula** $H_0$ deve ser um modelo de probabilidade bem definido sobre o processo gerador de dados.
- A **hip√≥tese alternativa** $H_1$ pode ser menos precisa, e representa o complementar de $H_0$.
    - Dessa forma, se aceitamos/rejeitamos $H_0$, ent√£o rejeitamos/aceitamos $H_1$, e vice-versa.
- Um Teste de Hip√≥teses √© tipicamente conduzido da seguinte maneira:
    1. Aproximamos a distribui√ß√£o de uma **estat√≠stica de teste** $T$ sob $H_0$ atrav√©s de simula√ß√£o e/ou teoria;
    2. Analisamos se, nessa distribui√ß√£o, a ocorr√™ncia do valor observado para a nossa estat√≠stica de teste $T_{obs}$ √© _t√≠pico_ ou _at√≠pico_, isto √©, se sua ocorr√™ncia por pura chance/aleatoriedade √© "alta" ou "baixa" (de acordo com algum **n√≠vel de signific√¢ncia** $\alpha$ pr√©-definido).
        - Quando a ocorr√™ncia de $T_{obs}$ por pura aleatoriedade √© considerada _baixa_, esse evento √© considerado **estatisticamente significante**, e logo rejeitamos $H_0$.
        - Quando a ocorr√™ncia de $T_{obs}$ por pura aleatoriedade √© considerada alta_, esse evento √© considerado **estatisticamente insignificante**, e logo aceitamos $H_0$.
- Existe uma rela√ß√£o intr√≠nseca entre Testes de Hip√≥teses com n√≠vel de signific√¢ncia $\alpha$ e Intervalos de Confian√ßa com n√≠vel de confian√ßa $\gamma = 1- \alpha$.
    - Em particular, conclus√µes tomadas com base em ambas as t√©cnicas **devem ser estritamente as mesmas**.
- Um **p-valor** $p$ √© uma maneira de quantificar, sob $H_0$, o qu√£o _extremo_ √© o valor de $T_{obs}$, na dire√ß√£o contr√°ria √† suportada por $H_0$ (ou na dire√ß√£o em favor de $H_1$.
    - Podemos formular nossas conclus√µes em um Teste de Hip√≥teses apenas com base nos p-valores, mas devemos tomar cuidado ao interpret√°-los!
