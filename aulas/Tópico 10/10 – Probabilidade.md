# T√≥pico 10 ‚Äì Probabilidade [<img src="images/colag_logo.svg" style="float: right; vertical-align: middle; width: 42px; height: 42px;">](https://colab.research.google.com/github/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas/T%C3%B3pico%2010/10%20%E2%80%93%20Probabilidade.ipynb) [<img src="images/github_logo.svg" style="float: right; margin-right: 12px; vertical-align: middle; width: 36px; height: 36px;">](https://github.com/urielmoreirasilva/urielmoreirasilva.github.io/blob/main/aulas/T%C3%B3pico%2010/10%20%E2%80%93%20Probabilidade.ipynb)

Vamos aprender o b√°sico da Teoria de Probabilidade.

### Resultados Esperados

1. Introduzir os conceitos de espa√ßo amostral, eventos, massa e densidade de probabilidade.
1. Aprender algumas propriedades b√°sicas de probabilidade.
1. Introduzir os conceitos de probabilidade condicional e independ√™ncia.

### Refer√™ncias
- [CIT, Cap√≠tulo 9](https://inferentialthinking.com/)

Material adaptado do [DSC10 (UCSD)](https://dsc10.com/) por [Flavio Figueiredo (DCC-UFMG)](https://flaviovdf.io/fcd/) e [Uriel Silva (DEST-UFMG)](https://urielmoreirasilva.github.io)

## Probabilidade

- Algumas coisas na vida s√£o _naturalmente_ aleat√≥rias.
- Por exemplo, quando lan√ßamos uma moeda ou um dado üé≤, n√£o sabemos o resultado de antem√£o, ent√£o podemos dizer que esse resultado √© _incerto_, ou _aleat√≥rio_.
- Por√©m, ainda que um resultado em particular seja incerto, podemos estudar a _regularidade_ com as quais certos resultados acontecem atrav√©s da **Teoria de Probabilidade**.

- Novamente tomando como exemplo o lan√ßamento de uma moeda "honesta", a **probabilidade** de observamos "cara" √© igual a probabilidade de observarmos "coroa", e ambas s√£o iguais a $\frac{1}{2}$.
- Outro exemplo √© o lan√ßamento de um lado de 6 faces: a probabilidade com que cada face ocorre √© de $\frac{1}{6}$.

- Apesar da Probabilidade ser uma √°rea da Estat√≠stica/Matem√°tica muito bem definida em termos formais, √© natural que busquemos diferentes _interpreta√ß√µes_ para o que uma probabilidade realmente _representa_.
- A interpreta√ß√£o "cl√°ssica" ou **frequentista** nos diz que, se pud√©ssemos repetir um **experimento aleat√≥rio** infinitas vezes, a **frequ√™ncia** com a qual um resultado ocorre √© sua probabilidade de ocorr√™ncia.
- Por outro lado, a interpreta√ß√£o "subjetiva" ou **Bayesiana** nos diz que a probabilidade de ocorr√™ncia de um resultado √© **diferente para cada indiv√≠duo**, e depende do qu√£o **prov√°vel** (ou **improv√°vel**) esse resultado √© relativo a todos os outros poss√≠veis resultados do experimento em quest√£o.

- Nesse curso, adotaremos a interpreta√ß√£o frequentista, e utilizaremos **frequ√™ncias relativas para estimar probabilidades**!
    - Veremos isso com mais detalhes nos T√≥picos 11 e 12.

### Terminologia b√°sica

**Experimento aleat√≥rio**: Um processo ou a√ß√£o cujo resultado √© aleat√≥rio.

- Exemplos:
    - lan√ßamento de um dado;
    - lan√ßamento de uma moeda duas vezes;
    - ocorr√™ncia de chuva no dia de hoje;
    - vit√≥ria do Galo na Libertadores 2024.

**Espa√ßo amostral**: O conjunto de todos os resultados poss√≠veis de um experimento aleat√≥rio.

- Nota√ß√£o: utilizamos $\Omega$ para denotar o espa√ßo amostral.

- Exemplos:
    - $\Omega = \{1, 2, 3, 4, 5, 6\}$;
    - $\Omega = \{(H, H), (H, T), (T, H), (T, T)\}$;
    - $\Omega = \{\text{chove}, \text{n√£o chove}\}$;
    - $\Omega = \{\text{vit√≥ria}, \text{derrota}\}$.

**Evento**: um conjunto espec√≠fico de resultados de interesse do experimento aleat√≥rio. 

- Nota√ß√£o: utilizamos $A$ para denotar um evento. Escrevemos $A \subseteq \Omega$, pois formalmente $A$ √© um _subconjunto_ de $\Omega$.

- Exemplos:
    - $A = \text{``n√∫mero par''} = \{2, 4, 6\}$;
    - $A = \text{``pelo menos 1 cara''} = \{(H, H), (H, T), (T, H)\}$;
    - $A = \text{``chove e vou me molhar''} = \{ \}$;
    - $A = \text{``felicidade da na√ß√£o atleticana''} = \{ \text{vit√≥ria} \}$.

**Probabilidade**: um n√∫mero entre 0 e 1 (equivalentemente, entre 0% e 100%) que descreve a probabilidade de um evento.

- Nota√ß√£o: utilizamos $P(A)$ para denotar a probabilidade de um evento $A$. Temos sempre $P(A) \in [0, 1]$.

- Exemplos:
    - $P(A) = 1/2 = 0.50 = 50\%$;
    - $P(A) = 3/4 = 0.75 = 75\%$;
    - $P(A) = 0 = 0\%$;
    - $P(A) = \,?$

- Nota: o evento $A = \{ \}$ √© denominado **evento imposs√≠vel**, pois $P(\{ \}) = 0$.
- Analogamente, o evento $A = \Omega$ √© denominado **evento certo**, pois $P(\Omega) = 1$.

### Resultados igualmente prov√°veis

- Se todos os resultados do espa√ßo amostral $\Omega$ forem _equiprov√°veis_ (isto √©, igualmente prov√°veis), ent√£o a probabilidade de qualquer evento $A \subseteq \Omega$ √© dada por

\begin{equation*}
    P(A) = \frac{\# \text{de elementos em } A}{\# \text{de elementos em } \Omega} = \frac{\#(A)}{\#(\Omega)}
\end{equation*}

#### Exemplo

- Suponha que lancemos uma moeda "justa" 3 vezes. Qual √© a probabilidade de vermos exatamente 2 caras?

O espa√ßo amostral nesse exemplo √© dado por $\Omega = \{(H, H, H), (H, H, T), (H, T, H), (H, T, T), (T, H, H), (T, H, T), (T, T, H), (T, T, T)\}$. 

Nosso evento de interesse √© $A = \{(H, H, T), (H, T, H), (T, H, H)\}$.

Dessa forma, como $\#(A) = 3$ e $\#(\Omega) = 2^3 = 8$, ent√£o $P(A) = 3/8$.

### Exerc√≠cio ‚úÖ

Suponha que voc√™ tenha tr√™s cartas: uma vermelha, uma azul e outra verde. 

Qual √© a probabilidade de voc√™ escolher uma das cartas aleatoriamente e ela ser verde, e ent√£o ‚Äì **sem devolv√™-la** ‚Äì voc√™ escolher outra carta aleatoriamente e ela ser vermelha?

A. $\frac{1}{9}$

B. $\frac{1}{6}$

C. $\frac{1}{3}$

D. $\frac{2}{3}$

E Nenhuma das op√ß√µes acima.

### Eventos mutuamente exclusivos

- Suponha que $A$ e $B$ sejam dois eventos **mutuamente exclusivos**.
- Isso significa que se $A$ acontecer, $B$ n√£o acontece, e vice-versa.
- Na linguagem de Teoria de Conjuntos, dizemos que $A$ e $B$ s√£o _disjuntos_, isto √©, _n√£o existe interse√ß√£o entre $A$ e $B$_.
- Formalmente, escrevemos $A \cap B = \{ \}$.

- Quando $A$ e $B$ s√£o mutuamente exclusivos, √© razo√°vel que a probabilidade de que o evento $\text{``} A \text{ ou } B \text{''}$ ocorra seja igual a **soma das probabilidades** de ocorr√™ncia de $A$ e $B$.
- Intuitivamente, $\text{``} A \text{ ou } B \text{''} = A \cup B$.
- Essa regra √© denominada de **regra da adi√ß√£o**.

Mais precisamente, a regra da adi√ß√£o diz que, para $A \cap B = \{ \}$,
\begin{equation*}
    P(A \text{ ou } B) = P(A) + P(B)
\end{equation*}

#### Exemplo

- Suponha que estejamos analisando o lan√ßamento de um dado de 6 faces. Qual √© a probabilidade de obtermos um 5 **ou** um 6?

O espa√ßo amostral nesse exemplo √© dado por $\Omega = \{1, 2, 3, 4, 5, 6\}$. 

Nossos eventos de interesse s√£o $A = \{ 5 \}$ e $B = \{ 6 \}$.

Dessa forma, como $A \cap B = \{ \}$, $A$ e $B$ s√£o mutuamente exclusivos, e $P(A \text{ ou } B) = P(A) + P(B)$.

Como todos os resultados s√£o igualmente prov√°veis e $\#(\Omega) = 6$, ent√£o $P(A) = \#(A) / \#(\Omega) = 1/6$ e $P(B) = \#(B) / \#(\Omega) = 1/6$.

Finalmente, aplicando a regra da adi√ß√£o, chegamos a $P(A \text{ ou } B) = P(A) + P(B) = 1/6 + 1/6 = 2/6 = 1/3$.

### Eventos complementares

- Suponha agora que estejamos interessados na probabilidade de que um evento $A$ **n√£o aconte√ßa**.
- Em Teoria dos Conjuntos, denominamos tais eventos de **complementares**.
- O complementar de $A$ (em $\Omega$) √© definido como $A^c$.
- Formalmente, denotamos $\text{``} A \text{ n√£o ocorrer} \text{''} \equiv A^c$.

- Podemos provar, utilizando a regra da adi√ß√£o, que
\begin{equation*}
    P(\text{``} A \text{ n√£o ocorrer} \text{''}) := P(A^c) = 1 - P(A)
\end{equation*}

- O resultado acima √© intuitivo, uma vez que os eventos $A$ e $\text{``} A \text{ n√£o ocorrer} \text{''}$ s√£o mutuamente exclusivos, e como um ou o outro _sempre_ ocorrem, a soma de suas probabilidades √© igual a 1.

#### Exemplo

- Suponha que $A = \{\text{chover hoje}\}$, e que $P(A) = 20\%$. Ent√£o $A^c = \{\text{n√£o chover hoje}\}$, e $P(\text{``} A \text{ n√£o ocorrer} \text{''}) = P(A^c) = 1 - P(A) = 80\%$.

### Eventos simult√¢neos

- Suponha agora que estejamos interessados na probabilidade de que **ambos** $A$ e $B$ ocorram.
- O evento de interesse aqui pode ser ent√£o denotado como $\text{``} A \text{ e } B \text{''}$.
- Intuitivamente, $\text{``} A \text{ e } B \text{''} = A \cap B$.
- √â comum denotarmos $P(\text{``} A \text{ e } B \text{''}) = P(A, B)$.

#### Exemplo

- Suponha que voc√™ lance um dado de 6 faces. Qual √© a probabilidade de o lan√ßamento ser igual a 3 ou menos, e ainda por cima um n√∫mero par?

O espa√ßo amostral nesse exemplo √© dado por $\Omega = \{1, 2, 3, 4, 5, 6\}$. 

Nossos eventos de interesse s√£o $A = \{ 1, 2, 3 \}$ e $B = \{ 2, 4, 6 \}$.

Dessa forma, temos $\text{``} A \text{ e } B \text{''} = A \cap B = \{ 2 \}$.

Como todos os resultados s√£o igualmente prov√°veis e $\#(\Omega) = 6$, ent√£o $P(A \cap B) = \#(A \cap B) / \#(\Omega) = 1/6$.

### Probabilidade Condicional

- Suponha agora que estejamos interessados na probabilidade de que $B$ ocorra, sabendo que $A$ j√° ocorreu.
- Nesse contexto, definimos a **probabilidade condicional** de $B$ dado $A$ por:

\begin{equation*}
P(\text{``} B \text{ dado } A \text{''}) \equiv P(B | A) := \frac{P(A, B)}{P(A)}
\end{equation*}

- Na probabilidade condicional de $B$ dado $A$, "restringimos" o espa√ßo amostral $\Omega$ a ser igual aos elementos contidos em $A$.
- Em outras palavras, o conhecimento da ocorr√™ncia de $A$ **aumenta** a probabilidade de ocorr√™ncia de $P(A, B)$, uma vez que aqui temos **mais informa√ß√£o** e logo **menos incerteza**.

- Para ilustrar esse ponto formalmente, note que se todos os elementos de $\Omega$ forem equiprov√°veis, temos que
\begin{equation*}
    P(B|A) = \frac{P(A, B)}{P(A)} = \frac{\frac{\#(A \cap B)}{\#(\Omega)}}{\frac{\#(A)}{\#(\Omega)}} = \frac{\#(A \cap B)}{\#(\Omega)} \cdot \frac{\#(\Omega)}{\#(A)} = \frac{\#(A \cap B)}{\#(A)}
\end{equation*}
o que corrobora nossa intui√ß√£o de que $A$ se torna o "novo espa√ßo amostral" quando condicionamos em sua ocorr√™ncia.

### Exerc√≠cio ‚úÖ

Suponha que voc√™ lance um dado de 6 lados e sabe apenas que o resultado √© igual a 3 ou menos. Qual √© a probabilidade de que o resultado seja um n√∫mero par?

A. $\frac{1}{2}$

B. $\frac{1}{3}$

C. $\frac{1}{4}$

D. Nenhuma das op√ß√µes acima.

### A regra da multiplica√ß√£o

- A **regra da multiplica√ß√£o** nos fornece uma maneira de calcular a probabilidade de ocorr√™ncia de ambos $A$ e $B$, sabendo qual √© a probabilidade **marginal** de $A$ e qual √© a probabilidade condicional de $B$ dado $A$.
- Mais especificamente, 

\begin{equation*}
    P(A, B) = P(A) \cdot P(B | A)
\end{equation*}

#### Exemplo (de novo!)

- Suponha que voc√™ lance um dado de 6 faces. Qual √© a probabilidade de o lan√ßamento ser igual a 3 ou menos, e ainda por cima um n√∫mero par?

O espa√ßo amostral nesse exemplo √© dado por $\Omega = \{1, 2, 3, 4, 5, 6\}$. 

Nossos eventos de interesse s√£o $A = \{ 1, 2, 3 \}$ e $B = \{ 2, 4, 6 \}$.

Sabemos que $P(A) = 1/2$ e que $P(B|A) = 1/3$.

Logo, utilizando a regra da multiplica√ß√£o, $P(A, B) = 1/2 \cdot 1/3 = 1/6$, assim como obtivemos anteriormente.

### Eventos independentes

- A no√ß√£o de **eventos independentes** surge naturalmente no contexto de Probabilidade Condicional quando fazemos a seguinte pergunta:

> "e se a ocorr√™ncia de $A$ n√£o afetar a ocorr√™ncia de $B$? ü§î"

- Formalmente, dois eventos $A$ e $B$ s√£o independentes se
\begin{equation*}
    P(B | A) = P(B)
\end{equation*}

- Agora, pela regra da multiplica√ß√£o, note que isso implica que
\begin{equation*}
    P(A, B) = P(A) \cdot P(B)
\end{equation*}

- Em geral, ambas as defini√ß√µes s√£o v√°lidas para eventos independentes, mas a consequ√™ncia de ambas √© a mesma: se $A$ e $B$ s√£o independentes, $P(B|A) = P(B)$ e $P(A|B) = P(A)$, de maneira que **o conhecimento da ocorr√™ncia de um evento n√£o impacta a probabilidade do outro**.

#### Exemplo

- Suponha que lancemos uma moeda justa repetidas vezes, de maneira independente uma da outra. Qual √© a probabilidade de observarmos 50 caras seguidas?

O espa√ßo amostral de _cada lan√ßamento_ nesse exemplo √© dado por $\Omega_i = \{H, T\}$, $i = 1, \ldots, 50$.

Nosso evento de interesse √© $(A_1, A_2, \ldots, A_{50})$, onde cada $A_i = \{ H \}$. 

Cada $A_i$ t√™m probabilidade igual a $P(A_i) = 1/2$.

Como os $A_i$ s√£o independentes, ent√£o $P(A_1, A_2, \ldots, A_{50}) = (\frac{1}{2})^{50}$.

### Exerc√≠cio ‚úÖ

Suponha que cada vez que voc√™ liga para sua av√≥ üëµ, a probabilidade de ela atender o telefone √© de $\frac{1}{3}$, independentemente se ela atendeu o telefone ou n√£o na √∫ltima liga√ß√£o. Se voc√™ ligar tr√™s vezes para sua av√≥ hoje, qual a chance de voc√™ conseguir falar com ela exatamente tr√™s vezes?

_Dica_: utilize a independ√™ncia e a complementariedade dos eventos.

A. $\frac{1}{3}$

B. $\frac{1}{9}$

C. $\frac{1}{27}$

D. $1$

E. Nenhuma das op√ß√µes acima.

### Booleanos

- A Teoria de Probabilidade √© _intrinsicamente_ ligada √† Teoria dos Conjuntos.
- Como vimos anteriormente, as opera√ß√µes entre vari√°veis booleanas tamb√©m s√£o naturalmente formuladas como opera√ß√µes entre conjuntos.
- Na pr√°tica, √© muito comum definirmos os eventos sobre os quais estamos interessados atrav√©s de opera√ß√µes entre booleanas nos nossos `arrays`, `DataFrames`, `Series`, `Lists`, etc; veremos isso mais adiante nos pr√≥ximos t√≥picos.

## Resumo

- O conjunto de todos os poss√≠veis resultados de um experimento aleat√≥rio √© denominado de **espa√ßo amostral**.
- Um **evento** √© uma cole√ß√£o de elementos de interesse do espa√ßo amostral. 
- A **probabilidade** de ocorr√™ncia de um evento pode ser interpretada como a **frequ√™ncia** com a qual esse evento ocorreria caso pud√©ssemos repetir o experimento aleat√≥rio infinitas vezes.
- Existem v√°rias regras para calcular probabilidades. Nesse curso analisaremos muitos casos especiais em que os elementos do espa√ßo amostral s√£o igualmente prov√°veis.
- Duas regras √∫teis para o c√°lculo das probabilidades de certos eventos s√£o:
    1. A **regra da adi√ß√£o**, que afirma que para quaisquer dois eventos **mutuamente exclusivos**, $P(A \text{ ou } B) = P(A) + P(B)$;
    1. A **regra da multiplica√ß√£o**, que afirma que para quaisquer dois eventos, $P(A, B) = P(B | A) \cdot P(A) \:$.
